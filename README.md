# ec2-imagebuilder-secure-proxy

CDK stack with an EC2 Image Builder component that installs a NGINX proxy which performs `wss://` to `tcp://` protocol conversion and JWT token validation.

Securing and modernising client access to TCP socket applications presents our customers with a unique set of challenges. How to authenticate client requests, how to enforce transit encryption and how to provide client access using standard web protocols. To increase complexity even further, our customers often require the implementation of these functionalities to be transparent, restricting any code or configuration changes to the TCP socket application. 

This project leverages the [EC2 Image Builder](https://aws.amazon.com/image-builder/) service to create an AMI ([Amazon Machine Images](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)) which includes a component that installs a custom build of the open-source [NGINX](https://nginx.org/en) proxy.

The custom AMI generated by the EC2 Image Builder can then be used to launch an EC2 instance which will provide:

* in-transit encryption of client connections using `wss://` ([Secure WebSocket](https://tools.ietf.org/html/rfc6455)) protocol
* authentication of client requests via the validation of a JWT token with an upstream oAuth server
* protocol conversion; `wss://` → `tcp://`, `tcp://` → `wss://`

----

* [Project overview](#project-overview)
* [Deploying the project](#deploying-the-project)
* [Configuring the project](#configuring-the-project)
  * [Create the Secure Proxy EC2 instance](#create-the-secure-proxy-ec2-instance)
  * [Create the Mock Servers EC2 instance](#create-the-mock-servers-ec2-instance)
* [Clean-up the project](#clean-up-the-project)
* [Executing unit tests](#executing-unit-tests)
* [Secure Proxy NGINX component](#secure-proxy-nginx-component)
    * [NGINX solution and licenses](#nginx-solution-and-licenses)
    * [NGINX configuration](#nginx-configuration)
    * [Managing the NGINX service](#managing-the-nginx-service)
    * [NGINX logging](#NGINX-logging)
        * [Error logging](#error-logging)
        * [Access logging](#access-logging)
        * [Log File Rotation](#log-file-rotation)
        * [NGINX logrotate default pattern](#nginx-logrotate-default-pattern)
        * [CloudWatch Logging](#cloudwatch-logging)
    * [NGINX security](#nginx-security)
        * [Securing the NGINX Process](#securing-the-nginx-process)
            * [Root master, unprivileged worker](#root-master,-unprivileged-worker)
            * [NGINX Chroot Jail](#nginx-chroot-jail)
        * [Secure access to the SSL certificates](#secure-access-to-the-ssl-certificates)
        * [JWT Validation](#jwt-validation)
    * [WebSocket client](#websocket-client)
        * [Request headers](#request-headers)
        * [Binary data](#binary-data)
    * [Known issues](#known-issues)
        * [LuaJIT warnings](#luajit-warnings)
        * [Websocket maximum frame size](#websocket-maximum-frame-size)
        * [Websocket text frames not supported](#websocket-text-frames-not-supported)
* [Mock Servers component](#mock-servers-component)
    * [TCP server](#tcp-server)
    * [oAuth server](#oauth-server)
* [Security](#security)
* [License](#license)

# Project Overview

The solution architecture discussed in this post is presented below:

![Solution Architecture](docs/assets/solution_architecture.png)

1. An EC2 Image Builder Pipeline is run which generates a Secure Proxy AMI. The generated AMI contains a [Secure Proxy NGINX component](#secure-proxy-nginx-component).
2. A secondary EC2 Image Builder Pipeline is run which generates a Mock Servers AMI which simulates the behaviour of a TCP socket application and an oAuth server. The Mock Servers AMI is provided for testing purposes only. In a customer environment, the functionalities of the Mock Servers AMI would be provided by the customer’s own TCP socket application and oAuth server.
3. An EC2 instance is launched in the Public subnet, using the Secure Proxy AMI.
4. An EC2 instance is launched in the Private subnet and added to an [Auto Scaling group](https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html) which is a target group of a [Network Load Balancer](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html). The EC2 instance is launched using the Mock Servers AMI.
5. Client applications can now interact with the Mock Servers EC2 instance running in the Private subnet:
    1. the client application obtains a JWT token via a `https://` request to the public facing Secure Proxy EC2 instance
    2. the client application establishes a `wss://` connection to the public facing Secure Proxy EC2 instance. The `wss://` request must contain a valid JWT token which is validated by the Secure Proxy EC2 instance.
    3. client application sends and receives data over the `wss://` connection. The Secure Proxy EC2 instance is providing protocol conversion capabilities such that the `wss://` frames are unpacked into standard TCP packets which are proxied to the TCP socket application. The TCP socket application is unaware that the client application is communicating over a `wss://` connection and the client application is unaware that the backend application is a TCP socket application.

A **note** regarding the SSL certificates that are used by the Secure Proxy NGINX component to encrypt data in-transit. The component uses [openssl](https://www.openssl.org/) to generate a self-signed certificate. The generated security certificate is not signed by a certificate authority. A self-signed certificate is useful for test purposes as they are simple to create, can be generated immediately and are free of charge. However, they do not provide all of the security properties that certificates signed by a CA aim to provide and are not recommended for use in production environments.

For production usage, customers may wish to consider the use of [AWS Certificate Manager for Nitro Enclaves](https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html). AWS Certificate Manager (ACM) for Nitro Enclaves allows customers to use public and private SSL/TLS certificates with web applications and web servers running on Amazon EC2 instances. ACM for Nitro Enclaves creates secure private keys, distributes the certificate and its private key to an enclave, and manages certificate renewals. The certificate's private key remains isolated in the enclave, preventing the instance, and its users, from accessing it. ACM for Nitro Enclaves works with NGINX servers running on Amazon EC2 instances to install the certificate and seamlessly replace expiring certificates.

# Deploying the project

The project code uses the Python flavour of the AWS CDK ([Cloud Development Kit](https://aws.amazon.com/cdk/)). In order to execute the project code, please ensure that you have fulfilled the [AWS CDK Prerequisites for Python](https://docs.aws.amazon.com/cdk/latest/guide/work-with-cdk-python.html).

The project code requires that the AWS account is [bootstrapped](https://docs.aws.amazon.com/de_de/cdk/latest/guide/bootstrapping.html) in order to allow the deployment of the CDK stack.

```
# navigate to project directory
cd ec2-imagebuilder-secure-proxy

# install and activate a Python Virtual Environment
python3 -m venv .venv
source .venv/bin/activate

# install dependant libraries
python -m pip install -r requirements.txt

# bootstrap the account to permit CDK deployments
cdk bootstrap
```

Upon successful completion of `cdk bootstrap`, the project is ready to be deployed.

```
cdk deploy
```

Following a successful deployment, verify that two new stacks have been created within the AWS account:

* `CDKToolkit`
* `EC2ImageBuilderSecureProxy-main`

Log into the AWS Console → navigate to the CloudFormation console:

![CloudFormation Stack verification](docs/assets/screenshots/01-cloudformation-stacks.png)

# Configuring the project

The CDK stack has created two EC2 Image Builder pipelines:

* `secure-proxy-pipeline-main`
* `mock-servers-pipeline-main`

To generate AMIs, these pipelines need to be *Run*.

1. Log into the AWS Console → navigate to the EC2 Image Builder console.
2. Click on `secure-proxy-pipeline-main` in the *Pipeline name* column of the *Image pipelines* table.
3. Click on the *Actions* button and select *Run pipeline*.
4. Repeat these steps for the `mock-servers-pipeline-main` pipeline.

At this point, you can observe that the pipelines are creating the AMIs. Depending on the number and type of components included within an AMI, the creation process can take a while. In the case of this project code, the AMI creation process can take up to one hour to complete.

![EC2 Image Builder AMI creation](docs/assets/screenshots/02-imagebuilder-image-building.png)

Once the EC2 Image Builder pipelines have completed the AMI creation process and the AMI *Status* is *Available*, these AMIs can be used to launch EC2 instances.

## Create the Secure Proxy EC2 instance

To create the Secure Proxy EC2 instance:

1. Log into the AWS Console → navigate to the EC2 console.
2. Select the *Launch instance* button → *Launch instance.*
3. In *Step 1: Choose an Amazon Machine Image (AMI)*, click on the *My AMIs* tab.
4. Select the AMI that has the name starting with **SecureProxy-main-ImageRecipe**.
5. In *Step 2: Choose an Instance Type*, choose instance type; **t2.medium**.
6. In *Step 3: Configure Instance Details*, make the following selections:
    1. For *Network*, select the VPC which includes the name **EC2ImageBuilderSecureProxy-main/secure-proxy-vpc-main**.
    2. For *Subnet*, select the VPC which includes the name **EC2ImageBuilderSecureProxy-main/secure-proxy-vpc-main/secure-proxy-subnet-public-main**.
    3. Ensure that *Auto-assign Public IP* is set as **Use subnet setting (Enable)**.
    4. For *IAM role,* select role **secure-proxy-ec2-instance-profile-main**.
7. In *Step 4: Add Storage*, continue with defaults.
8. In *Step 5: Add Tags*, continue with defaults.
9. In *Step 6: Configure Security Group*, make the following selections:
    1. Choose *Select an existing security group*.
    2. Select Security Group **secure-proxy-main**.
10. *Review and launch*.
11. If desired, create or use an existing [Amazon EC2 key pair](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html).

## Create the Mock Servers EC2 instance

In order to create the Mock Servers EC2 instance, the custom AMI needs to be include as part of a Launch Configuration.

1. Log into the AWS Console → navigate to the EC2 console.
2. Navigate to *Auto Scaling* → *Launch Configurations*.
3. Select *Create launch configurations*.
4. Name the new Launch Configuration as **SecureProxyLaunchConfig**.
5. In the AMI section, select the AMI with the name starting with **MockServers-main-ImageRecipie**.
6. In the *Instance Type* section, select the instance type as **t2.medium**.
7. In the *Security Groups* sections, *Select an existing security group* and select **nlb-traffic-main**.
8. If desired, create or use an existing [Amazon EC2 key pair](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html).
9. *Create launch configuration*

Associate the new Launch Configuration with the Auto Scaling group.

1. Log into the AWS Console → navigate to the EC2 console.
2. Navigate to *Auto Scaling* → *Auto Scaling Groups*
3. Select the auto scaling group with the name starting with **EC2ImageBuilderSecureProxy-main-secureproxyasg** and select *Edit* button.
4. In the *Launch configuration* section, select the Launch configuration option **SecureProxyLaunchConfig**.
5. Click *Update*.

Terminate old Auto Scaling Group instance in order to create instance based on new Launch Configuration.

1. Log into the AWS Console → navigate to the EC2 console.
2. Navigate to *Auto Scaling* → *Auto Scaling Groups*.
3. Under the *Instance management* tab, click the EC2 *Instance Id* link.
4. Click the *Instance state* button and choose *Terminate instance*.

The Auto Scaling group will automatically launch a new EC2 instance based on the **SecureProxyLaunchConfig** Launch configuration which includes the Mock Servers AMI. It can take several minutes before the new EC2 instance is registered with the Auto Scaling group as a healthy instance.

Check the EC2 Target Group to confirm if the instance has been successfully registered.

1. Log into the AWS Console → navigate to the EC2 console.
2. Navigate to *Load Balancing* → *Target Groups*.
3. Click on any Target Group associated with Load balancer; **secure-proxy-elb-main**
4. The *Healthy* count should be **1**.

# Testing the project

The project includes client code that can be used to execute test scenarios.

The client code will execute the following 4 test scenarios:

1. Retrieve an oAuth configuration via the EC2 Secure Proxy instance.
2. Retrieve an oAuth token via the EC2 Secure Proxy instance.
3. Establish a Secure Web Socket connection (containing a valid JWT token) with the EC2 Secure Proxy instance. Send and receive data along this connection. This test scenario validates that:
    1. the client provided a valid JWT token.
    2. the client is sending and receiving data over a Secure Web Socket connection.
    3. the EC2 Secure Proxy instance is performing `wss://` → `tcp://`, `tcp://` → `wss://` protocol conversion.
    4. the TCP socket application is receiving data as standard TCP traffic.
4. Attempt to establish a Secure Web Socket connection (containing an *invalid* JWT token) with the EC2 Secure Proxy instance. The expected outcome is a Http Code 403 Forbidden error.

In order to execute the test scenarios, the public IP address of the Secure Proxy EC2 instance is required.

1. Log into the AWS Console → navigate to the EC2 console.
2. Navigate to *Instances*.
3. Select the Secure Proxy EC2 instance.
4. In the *Details* tab, copy the *Public IPv4 address*.

The test scenarios are executed using the command below:

```
python client/secure_proxy_client.py -addr <<SECURE_PROXY_PUBLIC_IP_ADDR>>
```

![Testing the project](docs/assets/screenshots/03-client-test-scenarios.png)

By default, the project exposes `https://` and `wss://` services via the following ports:

* `https://<SECURE_PROXY_PUBLIC_IP_ADDR>:11080`
* `wss://<SECURE_PROXY_PUBLIC_IP_ADDR>:10000`

These port number can be configured, prior to CDK deployment, in the `proxySettings` section of the [cdk.json](cdk.json) file.

```
"proxySettings": {
    "jailBaseDir": "/nginx",
    "proxyBaseDir": "/etc/nginx",
    "proxyWorkerProcesses": "1",
    "proxyWorkerConnections": "20",
    "proxyCloudwatchLogGroup": "SecureProxy",
    "keepaliveTimeout": "120",
    "wssProxyBindPort": "10000",
    "oAuthProxyBindPort": "11080",
    "proxyPortScaleFactor": "1000",
    "websockifyConnectTimeout": "30s",
    "websockifyReadTimeout": "60s",
    "websockifySendTimeout": "60s"
}
```

Additionally, the [secure_proxy_client.py](client/secure_proxy_client.py) test scenario runner accepts additional `wss://` and `https://` port arguments.

```
python client/secure_proxy_client.py \
    # Public IP address or public DNS name of the Secure Proxy EC2 instance
    --ec2-address <<SECURE_PROXY_PUBLIC_IP_ADDR>> \
    # WSS port number of the Secure Proxy
    --wss-port <<WSS_PORT>> \
    # HTTPS port number of the Secure Proxy
    --https-port <<HTTPS_PORT>> 
```

# Clean-up the project

Project clean-up is a 4 step process:

1. Terminate the Secure Proxy EC2 instance.
2. Destroy the CDK stack.
3. Delete the **SecureProxyLaunchConfifg** launch configuration.
4. Delete the *CDKToolkit* stack from CloudFormation.

Terminate the SecureProxy EC2 instance.

1. Log into the AWS Console → navigate to the EC2 console.
2. Navigate to *Instances*.
3. Select the Secure Proxy EC2 instance.
4. Click the *Instance state* button and choose *Terminate instance.*

Delete the stack deployed by CDK with the command below:

```
cdk destroy
```

![Delete the stack](docs/assets/screenshots/04-delete-stack.png)

Delete the **SecureProxyLaunchConfifg** launch configuration.

1. Log into the AWS Console → navigate to the EC2 console.
2. Navigate to *Auto Scaling* → *Launch Configurations*.
3. Select the **SecureProxyLaunchConfifg** launch configuration.
4. Click the *Actions* button and choose *Delete launch configuration*.

Delete the CDKToolkit CloudFormation stack.

1. Log into the AWS Console → navigate to the *CloudFormation* console.
2. Navigate to *Stacks*.
3. Select the **CDKToolkit**.
4. Click the *Delete* button.

# Executing unit tests

Unit tests for the project can be executed via the commands below:

```bash
python3 -m venv .venv
source .venv/bin/activate
cdk synth && python -m pytest -v -c ./tests/pytest.ini
```

# Secure Proxy NGINX component

The Secure Proxy NGINX component provides a solution for:

  1. converting `wss://` (Secure WebSockets) requests to TCP requests and allowing for communication between a WSS client and a TCP socket server
  2. authenticating JWT tokens with an upstream oAuth server

## NGINX solution and licenses

The NGINX solution is built from [source](http://nginx.org/download/) and includes the following 3rd party NGINX modules:

| Module | Description | License |
|-------------|-------------|-------------|
| [nginx](https://www.nginx.com/) | Software load balancer, API gateway, and reverse proxy. | [BSD license](http://nginx.org/LICENSE) |
| [websockify-nginx-module](https://github.com/tg123/websockify-nginx-module) | An embedded port of the [Websockify](https://github.com/kanaka/websockify/) library into an NGINX module | [MIT license](https://github.com/tg123/websockify-nginx-module/blob/master/LICENSE) |
| [lua-nginx-module](https://github.com/openresty/lua-nginx-module) | This module is a core component of [OpenResty](https://openresty.org/). If you are using this module, then you are essentially using OpenResty. | [BSD license](https://github.com/openresty/lua-nginx-module#copyright-and-license) |
| [ngx_devel_kit](https://github.com/vision5/ngx_devel_kit) | The NDK is an NGINX module that is designed to extend the core functionality of the excellent NGINX webserver in a way that can be used as a basis of other NGINX modules. | [BSD license](https://github.com/vision5/ngx_devel_kit/blob/master/LICENSE) |

The following dependant libraries are required by the solution:

| Library | Description | License |
|-------------|-------------|-------------|
| [lua-cjson](https://github.com/mpx/lua-cjson) | Provides JSON support for Lua. | [MIT license](https://github.com/mpx/lua-cjson/blob/master/LICENSE) |
| [lua-resty-http](https://github.com/ledgetech/lua-resty-http) | Lua HTTP client cosocket driver for [OpenResty](http://openresty.org/) / [ngx_lua](https://github.com/openresty/lua-nginx-module). | [BSD license](https://github.com/ledgetech/lua-resty-http/blob/master/LICENSE) |
| [lua-resty-jwt](https://github.com/SkyLothar/lua-resty-jwt) | [JWT](http://self-issued.info/docs/draft-jones-json-web-token-01.html) for ngx_lua and LuaJIT. | [Apache license](https://github.com/SkyLothar/lua-resty-jwt/blob/master/LICENSE) |
| [lua-resty-session](https://github.com/bungle/lua-resty-session) | A secure, and flexible session library for OpenResty. | [BSD license](https://github.com/bungle/lua-resty-session/blob/master/LICENSE) |
| [lua-resty-string](https://github.com/openresty/lua-resty-string) | String utilities and common hash functions for ngx_lua and LuaJIT. | [BSD license](https://github.com/openresty/lua-resty-string#copyright-and-license) |
| [lua-resty-openidc](https://github.com/zmartzone/lua-resty-openidc) | A library for NGINX implementing the OpenID Connect Relying Party (RP) and/or the OAuth 2.0 Resource Server (RS) functionality. | [Apache license](https://github.com/zmartzone/lua-resty-openidc/blob/master/LICENSE.txt) |
| [lua-resty-core](https://github.com/openresty/lua-resty-core) | New FFI-based Lua API for ngx_http_lua_module and/or ngx_stream_lua_module. | [BSD license](https://github.com/openresty/lua-resty-core#copyright-and-license) |
| [lua-resty-hmac](https://github.com/jkeys089/lua-resty-hmac) | HMAC functions for ngx_lua and LuaJIT. | [BSD license](https://github.com/jkeys089/lua-resty-hmac#copyright-and-license) |

The solution leverages Lua and LuaJIT.

| Library | Description | License |
|-------------|-------------|-------------|
| [Lua](http://www.lua.org/) | Lua is a powerful, efficient, lightweight, embeddable scripting language. | [MIT license](https://www.lua.org/license.html) |
| [LuaJIT](https://luajit.org/) | Just-In-Time Compiler for Lua. | [MIT license](https://github.com/LuaJIT/LuaJIT/blob/v2.1/COPYRIGHT) |

## NGINX configuration

All NGINX compilation, installation and configuration takes place in [stacks/secureproxy/components/secureproxy/install_secure_proxy.template](stacks/secureproxy/components/secureproxy/install_secure_proxy.template).

NGINX requires the following configuration values, which are defined in [cdk.json](cdk.json), see `proxySettings` section:

| Item | Default value | Description |
|-------------|-------------|-------------|
| `jailBaseDir` | `/nginx` | Path to the root of the chroot directory for the NGINX proxy |
| `proxyBaseDir` | `/etc/nginx` | Path to the configuration directory for the NGINX proxy |
| `proxyWorkerProcesses` | `1` | The number of NGINX [worker_processes](https://www.nginx.com/blog/tuning-nginx/). The general rule is to assign 1 worker per CPU core |
| `proxyWorkerConnections` | `20` | The number of NGINX [worker_connections](https://www.nginx.com/blog/tuning-nginx/) |
| `proxyCloudwatchLogGroup` | `SecureProxy` | Stack specific CloudWatch LogGroup for the [nginx proxy logs](#nginx-logging) |
| `keepaliveTimeout` | `120` | Keep alive timeout for NGINX proxy connection |
| `wssProxyBindPort` | `10000` | Port that the NGINX proxy listens for incoming `wss://` requests |
| `oAuthProxyBindPort` | `11080` | Port that the NGINX proxy listens for incoming `https://` requests |
| `proxyPortScaleFactor` | `1000` | The scale factor to apply for port scaling. Port scaling is used to translate the incoming port number to a valid port number for the backend server. For example, if the incoming port is 10000, and the `proxyPortScaleFactor` is 1000, then the scaled port would be 9000 (10000-1000)) |
| `websockifyConnectTimeout` | `30s` | Connection timeout for the Websockify proxy |
| `websockifyReadTimeout` | `60s` | Websockify read timeout for upstream connection |
| `websockifySendTimeout` | `60s` | Websockify send timeout for upstream connection |

NGINX is installed as part of the EC2 Image Builder pipeline.

NGINX is installed on the AMI as a [systemd](https://en.wikipedia.org/wiki/Systemd) service: `nginx`.

The NGINX service is defined on the AMI at `/nginx/etc/systemd/system/nginx.service`.

NGINX is configured on the AMI via configuration file: `/nginx/etc/nginx/nginx.conf`.

## Managing the NGINX service

Some useful commands to manage the NGINX service are provided below:

```bash
# check the service status
sudo systemctl status -l nginx

# stop, start, restart the service
sudo systemctl stop nginx
sudo systemctl start nginx
sudo systemctl restart nginx
```

## NGINX logging

The Secure Proxy solution uses standard, out-of-the-box NGINX logging.

A detailed overview of NGINX logging is available at [Configuring Logging](https://docs.nginx.com/nginx/admin-guide/monitoring/logging/) on the NGINX website.

By default, the Secure Proxy defines three log files:

| Log file | Default path | Description |
|-------------|-------------|-------------|
| `nginx-error.log` | `/nginx/etc/nginx/logs/nginx-error.log` | Error log for the NGINX process |
| `http-error.log` | `/nginx/etc/nginx/logs/http-error.log` | Error log for the `wss://` requests |
| `http-access.log` | `/nginx/etc/nginx/logs/http-access.log` | Access log for the `wss://` requests |

### Error logging

NGINX error logs support the following log levels; `warn`, `error`, `crit`, `alert` and `emerg`.

An example NGINX error log definition is provided below.

```yaml
error_log /etc/nginx/logs/http-error.log debug;
```

### Access logging

NGINX access logs can be customized according to a preferred logging pattern.

An example NGINX access log definition is provided below.

```yaml
log_format main 'remote_addr=\$remote_addr remote_user=\$remote_user timestamp=[\$time_local] request="\$request" '
                'status=\$status bytes_sent=\$body_bytes_sent http_ref="\$http_referer" http_ua="\$http_user_agent" '
                'req_time=\$request_time up_addr=\$upstream_addr up_con_time="\$upstream_connect_time" '
                'up_head_time="\$upstream_header_time" up_res_time="\$upstream_response_time" '
                'up_status=\$upstream_status up_bytes_s=\$upstream_bytes_sent up_bytes_r=\$upstream_bytes_received';

access_log /etc/nginx/logs/http-access.log main;
```

A full listing of the available variables that can be logged within the access log can be found at [Alphabetical index of variables](http://nginx.org/en/docs/varindex.html).

### Log File Rotation

By design, NGINX does not manage log file rotation. In modern Linux operating systems, log file rotation is an operating system concern not a concern of individual services.

For this reason, NGINX log rotation should be managed by an external process. The most common process for managing log file rotation in Linux is [Logrotate](https://linux.die.net/man/8/logrotate) which is installed by default on Amazon Linux 2.

The [logrotate man page](https://linux.die.net/man/8/logrotate) explains how `logrotate` should be used and configured.

As a starting point, the [stacks/secureproxy/components/secureproxy/install_secure_proxy.template](stacks/secureproxy/components/secureproxy/install_secure_proxy.template) file contains a default logrotate pattern for the three NGINX log files.

### NGINX logrotate default pattern

An example default logrotate pattern for NGINX is shown below, as defined in the [stacks/secureproxy/components/secureproxy/install_secure_proxy.template](stacks/secureproxy/components/secureproxy/install_secure_proxy.template) file.

```bash
/nginx/etc/nginx/logs/nginx-error.log {
    su root docker
    missingok
    notifempty
    weekly
    compress
        delaycompress # Workaround for files being incorrectly removed
    create 0644 root root
    rotate 20
    size=30M
    postrotate
        /usr/sbin/chroot /nginx /usr/sbin/nginx -s reload
    endscript
        sharedscripts
}
EOF
```

### CloudWatch Logging

All of the above mentioned log files generated by NGINX are pushed to a CloudWatch Log Group with the following details:

| File Path | Log Group | Log Stream |
|-------------|-------------|-------------|
| `/nginx/etc/nginx/logs/nginx-error.log*` | SecureProxy | `{instance_id}/nginx/etc/nginx/logs/nginx-error.log` |
| `/nginx/etc/nginx/logs/http-error.log*` | SecureProxy | `{instance_id}/nginx/etc/nginx/logs/http-error.log` |
| `/nginx/etc/nginx/logs/http-access.log*` | SecureProxy | `{instance_id}/nginx/etc/nginx/logs/http-access.log` |

The CloudWatch Log Group has a retention period of *14 days/2 weeks*.

By default, the [CloudWatch Agent](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html) is configured using a JSON file at: `/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json`.

A sample configuration is provided below for illustrative purposes.

```json
{
  "logs":{
    "logs_collected":{
      "files":{
        "collect_list":[
          {
            "file_path":"/nginx/etc/nginx/logs/nginx-error.log*",
            "log_group_name":"SecureProxy",
            "log_stream_name":"{instance_id}/nginx/etc/nginx/logs/nginx-error.log"
          },
          {
            "file_path":"/nginx/etc/nginx/logs/http-error.log*",
            "log_group_name":"SecureProxy",
            "log_stream_name":"{instance_id}/nginx/etc/nginx/logs/http-error.log"
          },
          {
            "file_path":"/nginx/etc/nginx/logs/http-access.log*",
            "log_group_name":"SecureProxy",
            "log_stream_name":"{instance_id}/nginx/etc/nginx/logs/http-access.log*"
          }
        ]
      }
    }
  }
}
```
Configuration of the CloudWatch Agent takes place in [stacks/secureproxy/components/secureproxy/install_secure_proxy.template](stacks/secureproxy/components/secureproxy/install_secure_proxy.template).

## NGINX security

The key elements for security of the Secure Proxy component are:

1. Securing the NGINX process
2. Secure access to the SSL certificates
3. JWT Validation

### Securing the NGINX Process

The NGINX process has been secured using the following approach.

1. Root master, unprivileged workers
2. NGINX Chroot Jail

#### Root master, unprivileged worker

NGINX lauches as a master process with the root user. This is to ensure that the NGINX master process can have secure and exclusive access to the SSL certificates.

NGINX then spawns worker processes (the number of processes corresponds to the `worker_processes` value defined in `nginx.conf`) to handle the incoming requests which run as the unprivileged `nginx` user. The unprivileged `nginx` user does not have access to the SSL certificates and does not support interactive login (shell set to `/sbin/nologin`).

#### NGINX Chroot Jail

The NGINX process has been restricted to a limited part of the file system using Linux's in-built [chroot](https://en.wikipedia.org/wiki/Chroot) functionality.

A chroot on Unix operating systems is an operation that changes the apparent root directory for the current running process and its children. A program that is run in such a modified environment cannot name (and therefore normally cannot access) files outside the designated directory tree.

The NGINX process, by default, is chrooted to the directory `/nginx`. The `/nginx` chroot contains only the necessary directories, files and libraries to support NGINX operations. 

### Secure access to the SSL certificates

By default, NGINX is configured to retrieve its SSL certificates from `/nginx/etc/nginx/certs`.

The location of the SSL certificates are defined in `nginx.conf`:

```yaml
ssl_certificate     /etc/nginx/certs/servercert.pem;
ssl_certificate_key /etc/nginx/certs/serverkey.pem;
```

* `ssl_certificate` and `ssl_certificate_key` refer to the SSL certificates that are used to secure the connection between the `wss://` client to proxy connection.

The NGINX installation restricts access to the certificates directory to the root user only. Even in the case of the root user, the access is read-only. All other users are explicitly deined access to the certificates directory.

### JWT Validation

The Sexure Proxy supports validation of JWT tokens.

The JWT tokens are validated using a compliant, upstream [OpenID Connect](https://openid.net/connect/) server.

Within the NGINX context, JWT validation is performed using the 3rd party [lua-resty-openidc](https://github.com/zmartzone/lua-resty-openidc) library.

The [lua-resty-openidc](https://github.com/zmartzone/lua-resty-openidc) GitHub page provides various configuration examples.

## WebSocket client

The Secure Proxy backend component supports Secure WebSocket connections. 

### Request headers

The WebSocket client is expected to provide the following request headers:

| Header | Default value | Description |
|-------------|-------------|-------------|
| `Sec-WebSocket-Protocol` | `binary` |  The [Sec-WebSocket-Protocol](https://datatracker.ietf.org/doc/html/rfc6455#section-11.3.4) header field is used in the WebSocket opening handshake. It is sent from the client to the server and back from the server to the client to confirm the subprotocol of the connection.  This enables scripts to both select a subprotocol and be sure that the server agreed to serve that subprotocol. |
| `Sec-WebSocket-Key` | random-key e.g. `n2wfgJF+qto2ahU4+aoNkQ==` |  The [Sec-WebSocket-Key](https://datatracker.ietf.org/doc/html/rfc6455#page-57) header field is used in the WebSocket opening handshake. It is sent from the client to the server to provide part of the information used by the server to prove that it received a valid WebSocket opening handshake.  This helps ensure that the server does not accept connections from non-WebSocket clients (e.g., HTTP clients) that are being abused to send data to unsuspecting WebSocket servers. The Sec-WebSocket-Key header field MUST NOT appear more than once in an HTTP request. |
| `Sec-WebSocket-Version` | `13` |  The [Sec-WebSocket-Version](https://datatracker.ietf.org/doc/html/rfc6455#page-60) header field is used in the WebSocket opening handshake. It is sent from the client to the server to indicate the protocol version of the connection. This enables servers to correctly interpret the opening handshake and subsequent data being sent from the data, and close the connection if the server cannot interpret that data in a safe manner.  The Sec-WebSocket-Version header field is also sent from the server to the client on WebSocket handshake error, when the version received from the client does not match a version understood by the server.  In such a case, the header field includes the protocol version(s) supported by the server. Note that there is no expectation that higher version numbers are necessarily backward compatible with lower version numbers. |
| `Upgrade` | `websocket` |  The HTTP 1.1 (only) [Upgrade header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Upgrade) can be used to upgrade an already established client/server connection to a different protocol (over the same transport protocol). For example, it can be used by a client to upgrade a connection from HTTP 1.1 to HTTP 2.0, or an HTTP or HTTPS connection into a WebSocket. |
| `Authorization` | `Bearer JWT_TOKEN` |  The HTTP Authorization request header contains the credentials to authenticate a user agent with a server. The `Bearer` OAuth Access Token Type must contain the OIDC JWT token value. |

#### Binary data

The WebSocket client must ensure that it is sending its payload using the `binary` method.

Text payloads can be converted into byte arrays in order to send the data in the WebSocket `binary` format. It is also important that each payload ends with a [LF New Line character](https://en.wikipedia.org/wiki/Newline), specifically the string `\n`.

Two illustrative examples, in Python and NodeJs respectively, demonstrate how to send a `binary` payload as part of a WebSocket client request.

*Python*

```python
# pip install websocket
import websocket

header={
    'Authorization': f"Bearer {jwt_val}", # jwt_val is a JWT token obtained from an OIDC server
    'Sec-WebSocket-Key': 'n2wfgJF+qto2ahU4+aoNkQ==',
    'Sec-WebSocket-Protocol': 'binary',
    'Sec-WebSocket-Version': '13',
    'Upgrade': 'websocket'
}

ws = websocket.create_connection(
    self.url,
    sslopt={"cert_reqs": ssl.CERT_NONE,
            "check_hostname": False
    },
    header=header
)

NEW_LINE_CHAR = "\n" # NOTE: is is important to include a new line char as the final char of your payload
payload = "Hello World" + NEW_LINE_CHAR
bytearray(payload.encode()) # convert the string to a bytearray payload
ws.send_binary(payload_with_newline)
bin_answer = ws.recv_frame()
print("----BINARY RESPONSE CODE---")
print(websocket.ABNF.OPCODE_MAP[bin_answer.opcode])
print("----BINARY RESPONSE DATA---")
response = bytearray(bin_answer.data).decode()
print(f"Received response: {response}")
ws.close()
```

*NodeJs*

```javascript
// npm install websocket
// npm install string-to-arraybuffer
import WebSocket from 'ws';
const str2Ab =require('string-to-arraybuffer')

const NEW_LINE_CHAR = "\n" // NOTE: is is important to include a new line char as the final char of your payload
const payload = "Hello World" + NEW_LINE_CHAR
const payloadAsArrayBuffer = str2Ab(payload)

const headers = {
    'Authorization': f"Bearer " + jwt_val, // jwt_val is a JWT token obtained from an OIDC server
    'Sec-WebSocket-Key': 'n2wfgJF+qto2ahU4+aoNkQ==',
    'Sec-WebSocket-Protocol': 'binary',
    'Sec-WebSocket-Version': '13',
    'Upgrade': 'websocket'
}

const ws = new WebSocket('ws://www.host.com/path', 'binary', headers);
ws.on('open', function open() {
  ws.send(payloadAsArrayBuffer);
});
```

## Known issues

Below is a list of known issues with the Secure Proxy solution.

### LuaJIT warnings

Within the NGINX logs, you may see output similar to that shown below:

```bash
Aug 13 10:10:53 ip-172-31-16-141.ec2.internal chroot[3476]: nginx: [alert] detected a LuaJIT version which is not OpenResty's; many optimizations will be disabled and performance will be compromised (see https://github.com/openresty/luajit2 for OpenResty's LuaJIT or, even better, consider using the OpenResty releases from https://openresty.org/en/download.html)
Aug 13 10:10:54 ip-172-31-16-141.ec2.internal chroot[3476]: nginx: [alert] [lua] base.lua:41: use of lua-resty-core with LuaJIT 2.0 is not recommended; use LuaJIT 2.1+ instead
Aug 13 10:10:54 ip-172-31-16-141.ec2.internal chroot[3476]: nginx: [alert] [lua] lrucache.lua:16: use of lua-resty-lrucache with LuaJIT 2.0 is not recommended; use LuaJIT 2.1+ instead
```

As of the time of writing (08/2021), the LuaJIT 2.1+ library that the alert log message references is in a beta stage, [LuaJIT releases](https://github.com/LuaJIT/LuaJIT/releases). Until LuaJIT 2.1 becomes stable, it is recommended to remain on the current stable version LuaJIT v2.0.5.

Please note that upgrading the LuaJIT version to 2.1 may require a cascade of updates in dependant components so any upgrade should be throughly tested.

### Websocket maximum frame size

The [websockify-nginx-module](https://github.com/tg123/websockify-nginx-module), which provides the `wss://` to `tcp://` protocol conversion, enforces a fixed limit for websocket maximum frame size.

The websocket maximum frame size is defined as `65535`.

This websocket maximum frame size is defined in:

* [websocket.h](https://github.com/tg123/websockify-nginx-module/blob/master/websocket.h), see `#define MAX_WEBSOCKET_FRAME_SIZE 65535`
* [ngx_http_websockify_module.c](https://github.com/tg123/websockify-nginx-module/blob/master/ngx_http_websockify_module.c), see code block below:

```c
header_length = websocket_server_decode_next_frame(&frame, buf, size);

    if (header_length == NGX_ERROR) {
        ngx_log_error(NGX_LOG_ERR, c->log, 0,
                      "%s: decoding websocket frame > 65535 is not supported!",
                      WEBSOCKIFY_FUNC);
        return NGX_ERROR;
    }
```

If the websocket maximum frame size limit is too restrictive, the [websockify-nginx-module](https://github.com/tg123/websockify-nginx-module) code should be modified appropriately and recomplied into NGINX.

See [stacks/secureproxy/components/secureproxy/install_secure_proxy.template](stacks/secureproxy/components/secureproxy/install_secure_proxy.template) for example of NGINX module compilation:

```yaml
CONFIG="\
    --prefix=/etc/nginx \
    --sbin-path=/usr/sbin/nginx \
    --modules-path=/usr/lib/nginx/modules \
    --conf-path=/etc/nginx/nginx.conf \
    --error-log-path=/var/log/nginx/error.log \
    --http-log-path=/var/log/nginx/access.log \
    --pid-path=/var/run/nginx.pid \
    --lock-path=/var/run/nginx.lock \
    --http-client-body-temp-path=/var/cache/nginx/client_temp \
    --http-proxy-temp-path=/var/cache/nginx/proxy_temp \
    --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \
    --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \
    --http-scgi-temp-path=/var/cache/nginx/scgi_temp \
    --user=nginx \
    --group=nginx \
    --with-http_ssl_module \
    --with-http_realip_module \
    --with-http_addition_module \
    --with-http_sub_module \
    --with-http_dav_module \
    --with-http_flv_module \
    --with-http_mp4_module \
    --with-http_gunzip_module \
    --with-http_gzip_static_module \
    --with-http_random_index_module \
    --with-http_secure_link_module \
    --with-http_stub_status_module \
    --with-http_auth_request_module \
    --with-http_xslt_module=dynamic \
    --with-http_image_filter_module=dynamic \
    --with-http_geoip_module=dynamic \
    --with-threads \
    --with-stream \
    --with-stream_ssl_module \
    --with-stream_ssl_preread_module \
    --with-stream_realip_module \
    --with-stream_geoip_module=dynamic \
    --with-http_slice_module \
    --with-mail \
    --with-mail_ssl_module \
    --with-compat \
    --with-file-aio \
    --with-http_v2_module \
    --add-module=${BUILD_DIR}/websockify-nginx-module-${WEBSOCKIFY_NGINX_MODULE_VERSION} \
    --add-module=${BUILD_DIR}/lua-nginx-module-${LUA_NGINX_MODULE_VERSION} \
    --add-module=${BUILD_DIR}/ngx_devel_kit-${NGINX_DEV_VERSION}"
```

### Websocket text frames not supported

The [websockify-nginx-module](https://github.com/tg123/websockify-nginx-module), which provides the `wss://` to `tcp://` protocol conversion, does not support the sending of text frames.

Not supporting text frames is by design, as [described by the author of the library](https://github.com/novnc/websockify/issues/365):

> The WebSocket protocol is a bit of an oddball, so it has two modes of sending stuff. Either as text, or as raw data. But we need to proxy to normal TCP services which only sees data. So we naturally only use the raw data mode of WebSockets. The older code did accept incoming text messages and mixed those in with any data messages. But it would only send data messages back, so we ended up in some kind of jumble. So now we keep things sane and only accept data messages. From JavaScript that means you need to avoid sending text strings and use data types such as Uint8Array. Basically use the same data type as you are getting back in your message events.

The workaround is to send data in binary format, as described in [Binary data](#binary-data).

## Mock Servers component

The Mock Servers component is provided for testing purposes only and includes docker images which simulate the behaviour of a TCP socket application and an oAuth server.

### TCP Server

The TCP socket application functionality is provided by docker image; https://hub.docker.com/r/venilnoronha/tcp-echo-server/.

The docker image is used in accordance with its BSD-style license; https://github.com/venilnoronha/tcp-echo-server/blob/master/LICENSE.

The port number that the TCP socket application listens on is configured in the [cdk.json](cdk.json) file via the `tcpServerPort` parameter.

### oAuth Server

oAuth server functionality is provided by docker image; https://github.com/navikt/mock-oauth2-server.

The docker image is used in accordance with its MIT license; https://github.com/navikt/mock-oauth2-server/blob/master/LICENSE.

The port number that the mock oAuth server listens on is configured in the [cdk.json](cdk.json) file via the `oAuthServerPort` parameter.

# Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

# License

This library is licensed under the MIT-0 License. See the LICENSE file.